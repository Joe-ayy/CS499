{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"SVHN_Model_Single.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"metadata":{"id":"NC_Ge_JuanPP","colab_type":"text"},"cell_type":"markdown","source":["# **Libraries We'll Be Using**"]},{"metadata":{"id":"zizXMhYgasQu","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"a27df5f5-32c8-4f61-e720-66ee7c99394c","executionInfo":{"status":"ok","timestamp":1555008072609,"user_tz":240,"elapsed":2267,"user":{"displayName":"Seth Luttrell","photoUrl":"https://lh3.googleusercontent.com/-SEkj6qPyAjc/AAAAAAAAAAI/AAAAAAAAAFI/4-FBGT3W4ro/s64/photo.jpg","userId":"12602368811362108630"}}},"cell_type":"code","source":["import numpy as np\n","import h5py\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn import preprocessing\n","from sklearn.metrics import accuracy_score, f1_score\n","\n","from keras import regularizers\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Flatten, BatchNormalization\n","from keras.layers.convolutional import Conv2D, MaxPooling2D\n","from keras.layers.core import Activation\n","\n","from keras.optimizers import RMSprop"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"metadata":{"id":"ZxhSUM8HInM9","colab_type":"text"},"cell_type":"markdown","source":["# **Loading Preprocessed Dataset**"]},{"metadata":{"id":"KbCGA0-PL0LD","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":118},"outputId":"54b704f9-201e-456a-d9ca-353478af69f4","executionInfo":{"status":"ok","timestamp":1555008087931,"user_tz":240,"elapsed":813,"user":{"displayName":"Seth Luttrell","photoUrl":"https://lh3.googleusercontent.com/-SEkj6qPyAjc/AAAAAAAAAAI/AAAAAAAAAFI/4-FBGT3W4ro/s64/photo.jpg","userId":"12602368811362108630"}}},"cell_type":"code","source":["# open our uploaded file\n","svhn_data = h5py.File('SVHN_Preprocessed_Single.h5', 'r')\n","\n","# load the training, testing and validation set\n","X_train = svhn_data['X_train'][:]\n","y_train = svhn_data['y_train'][:]\n","X_test = svhn_data['X_test'][:]\n","y_test = svhn_data['y_test'][:]\n","X_val = svhn_data['X_val'][:]\n","y_val = svhn_data['y_val'][:]\n","\n","# close the file\n","svhn_data.close()\n","\n","\n","# check that our datasets are correct\n","print('Training X Shape: ', X_train.shape)\n","print('Training Y Shape: ', y_train.shape)\n","print('Testing X Shape: ', X_test.shape)\n","print('Testing Y Shape: ', y_test.shape)\n","print('Validation X Shape: ', X_val.shape)\n","print('Validation Y Shape: ', y_val.shape)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Training X Shape:  (58605, 32, 32, 1)\n","Training Y Shape:  (58605, 10)\n","Testing X Shape:  (26032, 32, 32, 1)\n","Testing Y Shape:  (26032, 10)\n","Validation X Shape:  (14652, 32, 32, 1)\n","Validation Y Shape:  (14652, 10)\n"],"name":"stdout"}]},{"metadata":{"id":"pebDNVRZcYXL","colab_type":"text"},"cell_type":"markdown","source":["# **Create a CNN Model**\n"]},{"metadata":{"id":"f_ML5H-M_368","colab_type":"text"},"cell_type":"markdown","source":["**Single-Output Model**"]},{"metadata":{"id":"R79wtoTkc1yB","colab_type":"code","colab":{}},"cell_type":"code","source":["def cnn_model_single():\n","\n","  weight_decay = 1e-4\n","\n","  model = Sequential()\n","\n","  # LAYER 1\n","  model.add(Conv2D(32, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay), \n","                   input_shape=X_train.shape[1:]))\n","  model.add(Activation('elu'))\n","  model.add(BatchNormalization())\n","  model.add(Conv2D(32, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n","  model.add(Activation('elu'))\n","  model.add(BatchNormalization())\n","  model.add(MaxPooling2D(pool_size=(2,2)))\n","  model.add(Dropout(0.2))\n","\n","\n","  # LAYER 2\n","  model.add(Conv2D(64, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n","  model.add(Activation('elu'))\n","  model.add(BatchNormalization())\n","  model.add(Conv2D(64, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n","  model.add(Activation('elu'))\n","  model.add(BatchNormalization())\n","  model.add(MaxPooling2D(pool_size=(2,2)))\n","  model.add(Dropout(0.3))\n","\n","\n","  # LAYER 3\n","  model.add(Conv2D(128, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n","  model.add(Activation('elu'))\n","  model.add(BatchNormalization())\n","  model.add(Conv2D(128, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n","  model.add(Activation('elu'))\n","  model.add(BatchNormalization())\n","  model.add(MaxPooling2D(pool_size=(2,2)))\n","  model.add(Dropout(0.4))\n","\n","\n","  # final layer has 11 activation layers\n","  # classes for 0-9 and a class for no digits\n","  model.add(Flatten())\n","  model.add(Dense(10, activation='softmax'))\n","\n","  return model"],"execution_count":0,"outputs":[]},{"metadata":{"id":"rRHhNE9Ed6aw","colab_type":"text"},"cell_type":"markdown","source":["**Compile, train, and save our CNN model**"]},{"metadata":{"id":"ISwYGYNFeqE9","colab_type":"code","colab":{}},"cell_type":"code","source":["# create and compile our model\n","model = cnn_model_single()\n","model.compile(loss='categorical_crossentropy', \n","              optimizer = RMSprop(lr=0.001, decay=1e-6), \n","              metrics=[\"accuracy\"])\n","\n","\n","# parameters for model fitting\n","batch_size = 128\n","epochs = 5\n","\n","# train the model\n","model.fit(x=X_train, y=y_train,\n","          validation_data=(X_val, y_val),\n","          batch_size=batch_size,\n","          epochs=epochs,\n","          verbose=1)\n","\n","\n","# save our model\n","model.save(\"SVHN_model_single.h5\")"],"execution_count":0,"outputs":[]},{"metadata":{"id":"qpUiK6iQ3Fe1","colab_type":"text"},"cell_type":"markdown","source":["**Check Model Accuracy**"]},{"metadata":{"id":"4ZTnCW2k3ReX","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":67},"outputId":"8bc037ab-c461-481c-eb29-710a2ebd0116","executionInfo":{"status":"ok","timestamp":1555008246642,"user_tz":240,"elapsed":152928,"user":{"displayName":"Seth Luttrell","photoUrl":"https://lh3.googleusercontent.com/-SEkj6qPyAjc/AAAAAAAAAAI/AAAAAAAAAFI/4-FBGT3W4ro/s64/photo.jpg","userId":"12602368811362108630"}}},"cell_type":"code","source":["from keras.models import load_model\n","model = load_model(\"SVHN_model_single.h5\")\n","\n","# display final accuracy on validation set\n","scores = model.evaluate(X_val, y_val, verbose=0)\n","print(\"Validation Accuracy: %.2f%%\" % (scores[1]*100))\n","\n","\n","# use our cnn model to make predictions on the testing set\n","test_predictions = model.predict(X_test,)\n","\n","# accuracy score\n","test_accuracy = accuracy_score(y_test, test_predictions.round())\n","print(\"Test Accuracy Score: %.2f%%\" % (test_accuracy*100))\n","\n","# f1 score\n","test_f1 = f1_score(y_test, test_predictions.round(), average='micro')\n","print(\"Test F1 Score: %.2f%%\" % (test_f1*100))"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Validation Accuracy: 92.62%\n","Test Accuracy Score: 91.36%\n","Test F1 Score: 92.87%\n"],"name":"stdout"}]},{"metadata":{"id":"sNSsaYSdrSa8","colab_type":"text"},"cell_type":"markdown","source":["**Dsiplay some predictions our model makes**"]},{"metadata":{"id":"LLENyjH8rXxj","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":269},"outputId":"583f99cc-0be2-4131-ca62-b63d37324b0d","executionInfo":{"status":"ok","timestamp":1555008500464,"user_tz":240,"elapsed":335,"user":{"displayName":"Seth Luttrell","photoUrl":"https://lh3.googleusercontent.com/-SEkj6qPyAjc/AAAAAAAAAAI/AAAAAAAAAFI/4-FBGT3W4ro/s64/photo.jpg","userId":"12602368811362108630"}}},"cell_type":"code","source":["import random\n","\n","# randomly select labels from the test dataset and see what the model predicted\n","for i in random.sample(range(0, len(X_test)), 5):\n","  print(\"Actual Label: \\t\\t\", np.argmax(y_test[i]))\n","  print(\"Predicted Label: \\t\", np.argmax(test_predictions[i]))\n","  print(\"\")"],"execution_count":15,"outputs":[{"output_type":"stream","text":["Actual Label: \t\t 5\n","Predicted Label: \t 5\n","\n","Actual Label: \t\t 0\n","Predicted Label: \t 0\n","\n","Actual Label: \t\t 8\n","Predicted Label: \t 8\n","\n","Actual Label: \t\t 5\n","Predicted Label: \t 5\n","\n","Actual Label: \t\t 6\n","Predicted Label: \t 6\n","\n"],"name":"stdout"}]}]}